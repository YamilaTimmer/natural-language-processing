{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9fa691",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d3b066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Er', 'ontstaan', 'gezwellen', '(tumoren).', 'Hoewel', 'het', 'woord', \"'tumor'\", 'voor', 'patiënten', 'vaak', 'een', 'angstige', 'bijklank', 'heeft', 'betekent', 'het', 'niet', 'meer', 'of', 'minder', 'dan', \"'zwelling'.\", 'Een', 'tumor', 'kan', 'zowel', 'goed-', 'als', 'kwaadaardig', 'zijn.', 'Een', 'goedaardige', 'tumor', 'wordt', 'ook', 'wel', 'benigne', 'genoemd,', 'een', 'kwaadaardige', 'maligne.', 'Bij', 'kanker', 'is', 'er', 'sprake', 'van', 'maligne', 'tumoren.', 'Kankerweefsel', 'geneest', 'niet', 'goed', 'en', 'gaat', 'makkelijk', 'bloeden.', 'Bloedverlies,', 'bijvoorbeeld', 'bij', 'ontlasting,', 'urine,', 'uit', 'de', 'tepel', 'of', 'bij', 'hoesten,', 'is', 'een', 'van', 'de', 'belangrijke', 'vroege', 'waarschuwingssymptomen.', 'De', 'gezwellen', 'drukken', 'op', 'andere', 'structuren', 'en', 'belemmeren', 'daarvan', 'de', 'werking.', 'Bij', 'de', 'darm', 'kan', 'bijvoorbeeld', 'passage', 'van', 'voedsel', 'onmogelijk', 'worden;', 'vanuit', '-', 'door', 'zwellingen', 'geblokkeerde', '-', 'zenuwbanen', 'in', 'het', 'ruggenmerg', 'kunnen', 'verlammingen', 'ontstaan;', 'in', 'botten', 'kunnen', 'breuken', 'optreden;', 'bij', 'zenuwen', 'kan', 'pijn', 'ontstaan;', 'bij', 'hersentumoren', 'ontstaan', 'er', 'ook', 'andere', 'neurologische', 'problemen', 'zoals', 'epilepsie.', 'Als', 'het', 'beenmerg', '-', 'waar', 'de', 'bloedaanmaak', 'plaatsvindt', '-', 'door', 'tumorweefsel', 'wordt', 'vervangen,', 'ontstaan', 'ernstige', 'bloedarmoede', 'en', 'stollingsstoornissen.', 'Kanker', 'veroorzaakt', 'vaak', 'verandering', 'van', 'de', 'stofwisseling', 'en', 'regulatie', 'daarvan', '(paraneoplastische', 'syndromen),', 'waaronder:', 'verhoogde', 'hormoonproductie;', 'hersen-,', 'zenuw-', 'en/of', 'spierafwijkingen;', 'bloed-', 'en', 'stollingsafwijkingen;', 'huidafwijkingen;', '', '', '', 'koorts', '(tumorkoorts);', 'cachexie', '(vermagering),', 'anorexie', '(verminderde', 'eetlust).']\n"
     ]
    }
   ],
   "source": [
    "from tokenizer_ivar import *\n",
    "x = filereader(\"test.txt\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35351615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E': 1, 'r': 117, 'o': 3, 'n': 138, 't': 109, 's': 6, 'a': 7, 'g': 8, 'e': 140, 'z': 10, 'w': 11, 'l': 12, '(': 13, 'u': 14, 'm': 15, ')': 16, '.': 136, 'H': 18, 'h': 19, 'd': 20, \"'\": 21, 'v': 22, 'p': 23, 'i': 24, 'ë': 25, 'k': 26, 'b': 27, 'j': 94, 'f': 29, '-': 30, ',': 31, 'B': 32, 'K': 33, 'c': 34, 'y': 35, 'D': 36, ';': 37, 'A': 38, ':': 39, '/': 40, 'x': 41, 'on': 42, 'nt': 43, 'ts': 44, 'ge': 45, 'tu': 46, 'um': 47, 'oe': 48, 'he': 49, 'et': 82, 'oo': 52, 'or': 107, 'va': 54, 'aa': 55, 'ee': 56, 'en': 139, 'an': 128, 'bi': 60, 'ij': 93, 'be': 62, 'er': 63, 'we': 64, 'mo': 65, 'wa': 66, 'bl': 68, 'lo': 69, 'de': 70, 'ar': 72, 've': 73, 'ont': 74, 'nts': 75, 'tst': 76, 'sta': 77, 'wel': 78, 'tum': 79, 'umo': 80, 'mor': 81, 'oor': 84, 'bij': 89, 'oed': 91, 'waa': 92, 'van': 95, 'blo': 96, 'loe': 97, 'aar': 98, 'ver': 99, 'onts': 100, 'ntst': 101, 'tsta': 102, 'staa': 103, 'taan': 104, 'tumo': 105, 'umor': 106, 'daar': 110, 'loed': 111, 'ontst': 112, 'ntsta': 113, 'tstaa': 114, 'staan': 115, 'tumor': 116, 'ontsta': 119, 'ntstaa': 120, 'tstaan': 121, 'ontstaa': 126, 'ntstaan': 127, 'ontstaan': 132}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def encoder(word_list, merge_attempts, min_merge_value):\n",
    "    token_dict = {}\n",
    "    token_value_dict = {}\n",
    "    counter = 1\n",
    "\n",
    "    # start vocab\n",
    "    for word_index in range(len(word_list)):\n",
    "        current_word = word_list[word_index]\n",
    "        for letter_index in range(len(current_word)):\n",
    "            letter = current_word[letter_index]\n",
    "            if token_value_dict.get(letter) == None:\n",
    "                token_value_dict[letter] = 1\n",
    "                token_dict[letter] = counter\n",
    "                counter += 1\n",
    "            else:\n",
    "                current_value = token_value_dict.get(letter)\n",
    "                new_value = current_value + 1\n",
    "                token_value_dict[letter] = new_value\n",
    "\n",
    "\n",
    "    def merge(word_list, merger_len, mergen_min_req):\n",
    "        merger_candidates = {}\n",
    "        \n",
    "        for word_index in range(len(word_list)):\n",
    "            current_word = word_list[word_index]\n",
    "            if len(current_word) < merger_len:\n",
    "                continue\n",
    "            else: \n",
    "                for letter_index in range(len(current_word)):\n",
    "                    if letter_index > merger_len:\n",
    "                        continue\n",
    "                    else:\n",
    "                        end_index = letter_index + merger_len\n",
    "                        candidate = current_word[letter_index: end_index]\n",
    "                        if merger_candidates.get(candidate) == None:\n",
    "                            merger_candidates[candidate] = 1\n",
    "                        else:\n",
    "                            current_value = merger_candidates.get(candidate)\n",
    "                            new_value = current_value + 1\n",
    "                            merger_candidates[candidate] = new_value\n",
    "\n",
    "        candidate_list = []\n",
    "        for candidate, value in merger_candidates.items():\n",
    "            if value >= mergen_min_req:\n",
    "                candidate_list.append(candidate)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        return candidate_list\n",
    "\n",
    "\n",
    "    for merge_attempt in range(merge_attempts):\n",
    "        merge_len = merge_attempt + 2\n",
    "        candidate_list = merge(word_list, merge_len, min_merge_value)\n",
    "        for candidate_index in range(len(candidate_list)):\n",
    "            new_candidate = candidate_list[candidate_index]\n",
    "            token_dict[new_candidate] = counter\n",
    "            counter += 1\n",
    "    \n",
    "    #resut =  merge(word_list,2,5)\n",
    "    #print(resut)\n",
    "    #print(token_dict)\n",
    "    #print(token_value_dict)\n",
    "\n",
    "    return token_dict\n",
    "\n",
    "encoder(x,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c916d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
