{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9fa691",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d3b066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Er', 'ontstaan', 'gezwellen', '(tumoren).', 'Hoewel', 'het', 'woord', \"'tumor'\", 'voor', 'patiënten', 'vaak', 'een', 'angstige', 'bijklank', 'heeft', 'betekent', 'het', 'niet', 'meer', 'of', 'minder', 'dan', \"'zwelling'.\", 'Een', 'tumor', 'kan', 'zowel', 'goed-', 'als', 'kwaadaardig', 'zijn.', 'Een', 'goedaardige', 'tumor', 'wordt', 'ook', 'wel', 'benigne', 'genoemd,', 'een', 'kwaadaardige', 'maligne.', 'Bij', 'kanker', 'is', 'er', 'sprake', 'van', 'maligne', 'tumoren.', 'Kankerweefsel', 'geneest', 'niet', 'goed', 'en', 'gaat', 'makkelijk', 'bloeden.', 'Bloedverlies,', 'bijvoorbeeld', 'bij', 'ontlasting,', 'urine,', 'uit', 'de', 'tepel', 'of', 'bij', 'hoesten,', 'is', 'een', 'van', 'de', 'belangrijke', 'vroege', 'waarschuwingssymptomen.', 'De', 'gezwellen', 'drukken', 'op', 'andere', 'structuren', 'en', 'belemmeren', 'daarvan', 'de', 'werking.', 'Bij', 'de', 'darm', 'kan', 'bijvoorbeeld', 'passage', 'van', 'voedsel', 'onmogelijk', 'worden;', 'vanuit', '-', 'door', 'zwellingen', 'geblokkeerde', '-', 'zenuwbanen', 'in', 'het', 'ruggenmerg', 'kunnen', 'verlammingen', 'ontstaan;', 'in', 'botten', 'kunnen', 'breuken', 'optreden;', 'bij', 'zenuwen', 'kan', 'pijn', 'ontstaan;', 'bij', 'hersentumoren', 'ontstaan', 'er', 'ook', 'andere', 'neurologische', 'problemen', 'zoals', 'epilepsie.', 'Als', 'het', 'beenmerg', '-', 'waar', 'de', 'bloedaanmaak', 'plaatsvindt', '-', 'door', 'tumorweefsel', 'wordt', 'vervangen,', 'ontstaan', 'ernstige', 'bloedarmoede', 'en', 'stollingsstoornissen.', 'Kanker', 'veroorzaakt', 'vaak', 'verandering', 'van', 'de', 'stofwisseling', 'en', 'regulatie', 'daarvan', '(paraneoplastische', 'syndromen),', 'waaronder:', 'verhoogde', 'hormoonproductie;', 'hersen-,', 'zenuw-', 'en/of', 'spierafwijkingen;', 'bloed-', 'en', 'stollingsafwijkingen;', 'huidafwijkingen;', '', '', '', 'koorts', '(tumorkoorts);', 'cachexie', '(vermagering),', 'anorexie', '(verminderde', 'eetlust).']\n"
     ]
    }
   ],
   "source": [
    "from tokenizer_ivar import *\n",
    "x = filereader(\"test.txt\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35351615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'E', 2: 'r', 3: 'o', 4: 'n', 5: 't', 6: 's', 7: 'a', 8: 'g', 9: 'e', 10: 'z', 11: 'w', 12: 'l', 13: '(', 14: 'u', 15: 'm', 16: ')', 17: '.', 18: 'H', 19: 'h', 20: 'd', 21: \"'\", 22: 'v', 23: 'p', 24: 'i', 25: 'ë', 26: 'k', 27: 'b', 28: 'j', 29: 'f', 30: '-', 31: ',', 32: 'B', 33: 'K', 34: 'c', 35: 'y', 36: 'D', 37: ';', 38: 'A', 39: ':', 40: '/', 41: 'x', 42: 'en', 43: 'an', 44: 'er', 45: 'or', 46: 'in', 47: 'el', 48: 'st', 49: 'ij', 50: 'aa', 51: 'oe', 52: 'ing', 53: 'oor', 54: 'oed', 55: 'on', 56: 'ge', 57: 'tu', 58: 'de', 59: 'tum', 60: 'tumor', 61: 'he', 62: 'ie', 63: 'aar', 64: 'van', 65: 'ver', 66: 'wel', 67: 'bij', 68: 'ont', 69: 'aan', 70: 'der', 71: 'is', 72: 'ijk', 73: 'bl', 74: 'ontst', 75: 'ontstaan', 76: 'en;', 77: 'zwel', 78: 'zwell', 79: 'het', 80: 'aak', 81: 'een', 82: 'ige', 83: 'ank', 84: 'of', 85: 'al', 86: 'daar', 87: 'ig', 88: 'ne', 89: 'gen', 90: 'en.', 91: 'ee', 92: 'sel', 93: 'bloed', 94: 'la', 95: 'uw', 96: 'ro', 97: 'voor', 98: 'pa', 99: 'be', 100: 'ken', 101: 'kan', 102: 'goed', 103: 'wor', 104: 'word', 105: 'oo', 106: 'igne', 107: 'anker', 108: 'ui', 109: 'ep', 110: 'waar', 111: 'ings', 112: 'ru', 113: 'op', 114: 'ander', 115: 'mer', 116: 'zen', 117: 'zenuw', 118: 're', 119: 'che', 120: 'ts', 121: 'af', 122: 'afw', 123: 'afwijk', 124: 'afwijking', 125: 'afwijkingen;', 126: 'gezwell', 127: 'gezwellen', 128: '(tumor', 129: 'en)', 130: 'ten', 131: 'vaak', 132: 'ang', 133: 'stige', 134: 'nie', 135: 'niet', 136: 'eer', 137: 'min', 138: 'minder', 139: 'zwelling', 140: 'Een', 141: 'zo', 142: 'als', 143: 'kw', 144: 'kwaa', 145: 'kwaadaar', 146: 'kwaadaard', 147: 'ijn', 148: 'wordt', 149: 'ook', 150: 'mal', 151: 'maligne', 152: 'Bij', 153: 'sp', 154: 'ak', 155: 'Kanker', 156: 'wee', 157: 'weef', 158: 'weefsel', 159: 'elijk', 160: 'bijvoor', 161: 'bijvoorbe', 162: 'bijvoorbeel', 163: 'bijvoorbeeld', 164: 'last', 165: 'uit', 166: 'bel', 167: 'sy', 168: 'andere', 169: 'em', 170: 'daarvan', 171: 'ar', 172: 'arm', 173: 'mo', 174: 'door', 175: 'merg', 176: 'ku', 177: 'kun', 178: 'kunn', 179: 'kunnen', 180: 'ontstaan;', 181: 'her', 182: 'hers', 183: 'hersen', 184: 'ische', 185: 'pro', 186: 'sto', 187: 'stol', 188: 'stoll', 189: 'stollings', 190: 'tie', 191: 'koor', 192: 'koorts', 193: 'xie', 194: '(ver', 195: 'Er', 196: '(tumoren)', 197: '(tumoren).', 198: 'Hoe', 199: 'Hoewel', 200: 'woor', 201: 'woord', 202: \"'tumor\", 203: \"'tumor'\", 204: 'pat', 205: 'pati', 206: 'patië', 207: 'patiën', 208: 'patiënten', 209: 'angstige', 210: 'bijk', 211: 'bijkl', 212: 'bijklank', 213: 'hee', 214: 'heef', 215: 'heeft', 216: 'bet', 217: 'bete', 218: 'beteken', 219: 'betekent', 220: 'meer', 221: 'dan', 222: \"'zwelling\", 223: \"'zwelling'\", 224: \"'zwelling'.\", 225: 'zowel', 226: 'goed-', 227: 'kwaadaardig', 228: 'zijn', 229: 'zijn.', 230: 'goedaar', 231: 'goedaard', 232: 'goedaardige', 233: 'ben', 234: 'benigne', 235: 'genoe', 236: 'genoem', 237: 'genoemd', 238: 'genoemd,', 239: 'kwaadaardige', 240: 'maligne.', 241: 'kanker', 242: 'spr', 243: 'sprak', 244: 'sprake', 245: 'tumoren.', 246: 'Kankerweefsel', 247: 'genee', 248: 'geneest', 249: 'gaa', 250: 'gaat', 251: 'mak', 252: 'makk', 253: 'makkelijk', 254: 'bloeden.', 255: 'Bl', 256: 'Bloed', 257: 'Bloedver', 258: 'Bloedverl', 259: 'Bloedverlie', 260: 'Bloedverlies', 261: 'Bloedverlies,', 262: 'ontlast', 263: 'ontlasting', 264: 'ontlasting,', 265: 'ur', 266: 'urin', 267: 'urine', 268: 'urine,', 269: 'tep', 270: 'tepel', 271: 'hoe', 272: 'hoest', 273: 'hoesten', 274: 'hoesten,', 275: 'belang', 276: 'belangr', 277: 'belangrijk', 278: 'belangrijke', 279: 'vr', 280: 'vroe', 281: 'vroege', 282: 'waars', 283: 'waarsc', 284: 'waarsch', 285: 'waarschuw', 286: 'waarschuwings', 287: 'waarschuwingssy', 288: 'waarschuwingssym', 289: 'waarschuwingssymp', 290: 'waarschuwingssympt', 291: 'waarschuwingssympto', 292: 'waarschuwingssymptom', 293: 'waarschuwingssymptomen.', 294: 'De', 295: 'dru', 296: 'druk', 297: 'drukken', 298: 'stru', 299: 'struc', 300: 'structu', 301: 'structur', 302: 'structuren', 303: 'belem', 304: 'belemmer', 305: 'belemmeren', 306: 'wer', 307: 'werk', 308: 'werking', 309: 'werking.', 310: 'darm', 311: 'pas', 312: 'pass', 313: 'passa', 314: 'passage', 315: 'voed', 316: 'voedsel', 317: 'onmo', 318: 'onmog', 319: 'onmogelijk', 320: 'worden;', 321: 'vanuit', 322: 'zwellingen', 323: 'gebl', 324: 'geblo', 325: 'geblok', 326: 'geblokk', 327: 'geblokkeer', 328: 'geblokkeerde', 329: 'zenuwb', 330: 'zenuwban', 331: 'zenuwbanen', 332: 'rug', 333: 'ruggen', 334: 'ruggenmerg', 335: 'verla', 336: 'verlam', 337: 'verlamm', 338: 'verlamming', 339: 'verlammingen', 340: 'bo', 341: 'bot', 342: 'botten', 343: 'bre', 344: 'breu', 345: 'breuken', 346: 'opt', 347: 'optre', 348: 'optred', 349: 'optreden;', 350: 'zenuwen', 351: 'pijn', 352: 'hersentumor', 353: 'hersentumoren', 354: 'neu', 355: 'neuro', 356: 'neurol', 357: 'neurolo', 358: 'neurolog', 359: 'neurologische', 360: 'probl', 361: 'problem', 362: 'problemen', 363: 'zoals', 364: 'epi', 365: 'epil', 366: 'epilep', 367: 'epileps', 368: 'epilepsie', 369: 'epilepsie.', 370: 'Al', 371: 'Als', 372: 'been', 373: 'beenmerg', 374: 'bloedaan', 375: 'bloedaanm', 376: 'bloedaanmaak', 377: 'pl', 378: 'plaa', 379: 'plaats', 380: 'plaatsv', 381: 'plaatsvin', 382: 'plaatsvind', 383: 'plaatsvindt', 384: 'tumorweefsel', 385: 'vervan', 386: 'vervangen', 387: 'vervangen,', 388: 'ern', 389: 'ernstige', 390: 'bloedarm', 391: 'bloedarmoed', 392: 'bloedarmoede', 393: 'stollingsst', 394: 'stollingsstoor', 395: 'stollingsstoorn', 396: 'stollingsstoornis', 397: 'stollingsstoorniss', 398: 'stollingsstoornissen.', 399: 'veroor', 400: 'veroorz', 401: 'veroorzaak', 402: 'veroorzaakt', 403: 'verander', 404: 'verandering', 405: 'stof', 406: 'stofw', 407: 'stofwis', 408: 'stofwissel', 409: 'stofwisseling', 410: 'reg', 411: 'regu', 412: 'regula', 413: 'regulatie', 414: '(pa', 415: '(par', 416: '(paran', 417: '(parane', 418: '(paraneop', 419: '(paraneoplast', 420: '(paraneoplastische', 421: 'syn', 422: 'synd', 423: 'syndro', 424: 'syndrom', 425: 'syndromen)', 426: 'syndromen),', 427: 'waaron', 428: 'waaronder', 429: 'waaronder:', 430: 'verh', 431: 'verhoo', 432: 'verhoog', 433: 'verhoogde', 434: 'hor', 435: 'hormo', 436: 'hormoon', 437: 'hormoonpro', 438: 'hormoonprod', 439: 'hormoonprodu', 440: 'hormoonproduc', 441: 'hormoonproductie', 442: 'hormoonproductie;', 443: 'hersen-', 444: 'hersen-,', 445: 'zenuw-', 446: 'en/', 447: 'en/of', 448: 'spi', 449: 'spier', 450: 'spierafwijkingen;', 451: 'bloed-', 452: 'stollingsafwijkingen;', 453: 'hui', 454: 'huid', 455: 'huidafwijkingen;', 456: '(tumorkoorts', 457: '(tumorkoorts)', 458: '(tumorkoorts);', 459: 'ca', 460: 'cache', 461: 'cachexie', 462: '(verm', 463: '(verma', 464: '(vermag', 465: '(vermager', 466: '(vermagering', 467: '(vermagering)', 468: '(vermagering),', 469: 'anor', 470: 'anore', 471: 'anorexie', 472: '(verminder', 473: '(verminderde', 474: 'eet', 475: 'eetl', 476: 'eetlu', 477: 'eetlust', 478: 'eetlust)'}\n"
     ]
    }
   ],
   "source": [
    "def encoder(word_list):\n",
    "    token_dict = {}\n",
    "    token_value_dict = {}\n",
    "    counter = 1\n",
    "\n",
    "    # start vocab\n",
    "    for word_index in range(len(word_list)):\n",
    "        current_word = word_list[word_index]\n",
    "        for letter_index in range(len(current_word)):\n",
    "            letter = current_word[letter_index]\n",
    "            if token_value_dict.get(letter) == None:\n",
    "                token_value_dict[letter] = 1\n",
    "                token_dict[letter] = counter\n",
    "                counter += 1\n",
    "            else:\n",
    "                current_value = token_value_dict.get(letter)\n",
    "                new_value = current_value + 1\n",
    "                token_value_dict[letter] = new_value\n",
    "    # tokenize original words 1 toker per letter\n",
    "    words_in_tokens = []\n",
    "    for word_index in range(len(word_list)):\n",
    "        current_word = word_list[word_index]\n",
    "        word_in_tokens = []\n",
    "        for letter_index in range(len(current_word)):\n",
    "            current_letter = current_word[letter_index]\n",
    "            new_token = token_dict.get(current_letter)\n",
    "            word_in_tokens.append(new_token)\n",
    "        words_in_tokens.append(word_in_tokens)\n",
    "    # reverse key value\n",
    "    reversed_token_dict = {}\n",
    "    for key,value in token_dict.items():\n",
    "        new_key = value\n",
    "        new_value = key\n",
    "        reversed_token_dict[new_key] = new_value\n",
    "\n",
    "\n",
    "    def pair_merger(token_lists, tokens_dict):\n",
    "        new_token_lists = []\n",
    "        temp_dict = {}\n",
    "        pair_dict = {}\n",
    "        for token_list_index in range(len(token_lists)):\n",
    "            current_token_list = token_lists[token_list_index]\n",
    "            if len(current_token_list) < 2:\n",
    "                continue\n",
    "            else:\n",
    "                end_token_index = 1\n",
    "                token_list_range = len(current_token_list)-1\n",
    "                for token_index in range(token_list_range):\n",
    "                    #print(current_token_list)\n",
    "                    first_token_string = tokens_dict.get(current_token_list[token_index])\n",
    "                    first_token = current_token_list[token_index]\n",
    "                    secon_token_string = tokens_dict.get(current_token_list[end_token_index])\n",
    "                    second_token = current_token_list[end_token_index]\n",
    "                    end_token_index += 1\n",
    "\n",
    "                    candidate = first_token_string + secon_token_string\n",
    "                    if temp_dict.get(candidate) == None:\n",
    "                        temp_dict[candidate] = 1\n",
    "                        pair_dict[candidate] = [first_token,second_token]\n",
    "                    else:\n",
    "                        current_value = temp_dict.get(candidate)\n",
    "                        new_value = current_value + 1\n",
    "                        temp_dict[candidate] = new_value\n",
    "\n",
    "        key_list = []\n",
    "        value_list = []\n",
    "        for key,value in temp_dict.items():\n",
    "            key_list.append(key)\n",
    "            value_list.append(value)\n",
    "\n",
    "        higest_value_index = value_list.index(max(value_list))\n",
    "        new_string_key = key_list[higest_value_index]\n",
    "\n",
    "        old_key_list = []\n",
    "        for key in tokens_dict.keys():\n",
    "            old_key_list.append(key)\n",
    "\n",
    "        new_token_key = max(old_key_list)+1\n",
    "        tokens_dict[new_token_key] = new_string_key\n",
    "        new_pair = pair_dict.get(new_string_key)\n",
    "        \n",
    "        for token_list_index in range(len(token_lists)):\n",
    "            current_token_list = token_lists[token_list_index]\n",
    "            temp_token_list = current_token_list.copy()\n",
    "            end_index = 1\n",
    "            for token_index in range(len(current_token_list)-1):\n",
    "                first_token = current_token_list[token_index]\n",
    "                second_token = current_token_list[end_index]\n",
    "\n",
    "                if first_token is new_pair[0] and second_token is new_pair[1]:\n",
    "                    temp_token_list[token_index] = new_token_key\n",
    "                    temp_token_list[end_index] = None\n",
    "                    end_index += 1\n",
    "                else:\n",
    "                    end_index += 1\n",
    "            # remove nonetypes\n",
    "            if None in (temp_token_list):\n",
    "                temp_token_list.remove(None)\n",
    "                while None in (temp_token_list):\n",
    "                    temp_token_list.remove(None)\n",
    "            new_token_lists.append(temp_token_list)\n",
    "\n",
    "        return new_token_lists, tokens_dict\n",
    "\n",
    "    result_token_list = words_in_tokens.copy()\n",
    "    result_token_dict = reversed_token_dict.copy()\n",
    "    max_len = 10\n",
    "    # condense all words into tokens\n",
    "    while max_len > 2:\n",
    "        result_token_list, result_token_dict = pair_merger(result_token_list,reversed_token_dict)\n",
    "        temp = []\n",
    "        for i in range(len(result_token_list)):\n",
    "            current_token_list = result_token_list[i]\n",
    "            temp.append(len(current_token_list))\n",
    "        \n",
    "        max_len = max(temp)\n",
    "    \n",
    "\n",
    "    return result_token_list,result_token_dict\n",
    "\n",
    "new_tokens, new_dict = encoder(x)\n",
    "print(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c916d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encwriter(token_dict):\n",
    "    with open(\"result.enc\",\"w\") as writer:\n",
    "        for key,value in token_dict.items():\n",
    "            line = str(key)+\":\"+str(value)+\"\\n\"\n",
    "            writer.write(line)\n",
    "    return\n",
    "\n",
    "Encwriter(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
