{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We gaan ons ngram script toepassen op de publicaties: \"Cancer: Its Cause and Treatment\" volume I & II van Lucius Duncan Bulkley. Om dit te doen moet de inhoud van de teksten eerst gedownload worden en worden opgeslagen als .txt bestand. Nadat dit gedaan is, kan het worden ingelezen met:",
   "id": "f34f3c75894045e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nlp import filereader\n",
    "text = filereader(\"gutenberg_cancer.txt\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vervolgens kan onze tokenizer worden aangeroepen om de tekst te veranderen in tokens. Hierbij wordt eerst de 'learn' command aangeroepen, waarbij hij wordt getraind op de meegegeven text en BPE uitvoert met de gegeven waarden voor max_tokens en min_freq. Vervolgens wordt de 'tokenize' command uitgevoerd, deze zet de meegegeven tekst om in tokens.\n",
   "id": "9ca0d9a28e9e2c99"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "python tokenize.py learn .\\gutenberg_cancer.txt 400 15"
   ],
   "id": "7c426a15c941eeef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%bash\n",
    "python tokenize.py tokenize .\\gutenberg_cancer.txt .\\gutenberg_cancer.enc"
   ],
   "id": "833b150f8b0c54ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We bepalen de waarschijnlijkheden van het opvolgen van een woord op een ngram met onderstaande code. Voor unigrams (setjes van telkens 1 woord) gaat dit heel simpel, het kiest \"random\" een woord, met als bijbehorende weights hoe vaak dit woord voorkomt in de tekst. Voor hogere vormen van ngrams, bijvoorbeeld bigrams en trigrams, werkt dit iets anders. Hier is er eerst bepaald welke tokens kunnen volgen op de huidige token(s). De bigram \"het kind\" kan bijvoorbeeld opgevolgd worden door de woorden \"eet\", \"slaapt\" of \"huilt\", bij de tokens is het ook zo dat elke token of verzameling van tokens specifieke woorden heeft waardoor het opgevolgd kan worden (althans, volgens de tekst waarop hij is getraind!). Ook hier weer geldt dat er \"willekeurig\" een van de mogelijkheden wordt gekozen, met daarbij ook nog de invloed van weights, die vaak voorkomende combinaties waarschijnlijker zullen maken om gekozen te worden voor de te genereren tekst.",
   "id": "52bede05af7f43e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%bash\n",
    "python ngram.py .\\gutenberg_cancer.tok 3 100 output.tok"
   ],
   "id": "da3b8ac50f3ec5a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Na bovenstaande code te runnen, is er een .tok bestand gegenereerd, dat gedecodeerd kan worden met de decode command van de tokenizer.",
   "id": "43c4417c3eb3963e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "python tokenize.py decode .\\output.tok .\\gutenberg_cancer.enc\n",
    "\n"
   ],
   "id": "96358999faa1ab10",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
