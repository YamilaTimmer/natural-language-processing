{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Toepassing Tokenizer\n",
    "\n",
    "In dit notebook passen we de tokenizer toe op 2 teksten, namelijk de wikipedia pagina van kanker in het Nederlands en in het Engels. Eerst gebruiken we de learn methode om de tokenizer te trainen op de teksten. Hieruit volgen .enc bestanden die alle gemaakte tokens en de bijbehorende tekens bevatten. We geven 2 argumenten mee, max_tokens om het maximale aantal tokens vast te stellen, in dit geval op 500. En min_freq, om vast te stellen hoe vaak een of meerdere tekens moeten voorkomen om een token te vormen, in dit geval is dat 5."
   ],
   "id": "6a15618c883dfbd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T09:58:45.485413Z",
     "start_time": "2025-12-12T09:58:43.577737Z"
    }
   },
   "cell_type": "code",
   "source": "!python tokenizer.py learn resources\\kanker_wiki.txt 500 5",
   "id": "141036ca36eebbe6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding saved: C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\kanker_wiki.enc\n",
      "BPE learned! Max tokens respected: 500\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T09:58:53.675758Z",
     "start_time": "2025-12-12T09:58:46.947958Z"
    }
   },
   "cell_type": "code",
   "source": "!python tokenizer.py learn resources\\cancer_wiki.txt 500 5",
   "id": "8bc83ff0de0bbef5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding saved: C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\cancer_wiki.enc\n",
      "BPE learned! Max tokens respected: 500\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We kunnen de aangemaakte tokens nu bekijken.",
   "id": "4e0a90965cf01c4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T10:15:10.859760Z",
     "start_time": "2025-12-12T10:15:10.852980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"kanker_wiki.enc\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ],
   "id": "62151b74a654c814",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:K\n",
      "2:a\n",
      "3:n\n",
      "4:k\n",
      "5:e\n",
      "6:r\n",
      "7:,\n",
      "8:i\n",
      "9:m\n",
      "10:d\n",
      "11:s\n",
      "12:c\n",
      "13:h\n",
      "14:L\n",
      "15:t\n",
      "16:j\n",
      "17::\n",
      "18:o\n",
      "19:p\n",
      "20:l\n",
      "21:g\n",
      "22:u\n",
      "23:'\n",
      "24:w\n",
      "25:v\n",
      "26:f\n",
      "27:z\n",
      "28:b\n",
      "29:;\n",
      "30:y\n",
      "31:.\n",
      "32:B\n",
      "33:-\n",
      "34:V\n",
      "35:N\n",
      "36:I\n",
      "37:2\n",
      "38:0\n",
      "39:8\n",
      "40:P\n",
      "41:(\n",
      "42:E\n",
      "43:M\n",
      "44:C\n",
      "45:)\n",
      "46:U\n",
      "47:H\n",
      "48:\"\n",
      "49:G\n",
      "50:R\n",
      "51:[\n",
      "52:1\n",
      "53:]\n",
      "54:T\n",
      "55:D\n",
      "56:x\n",
      "57:W\n",
      "58:é\n",
      "59:ó\n",
      "60:6\n",
      "61:4\n",
      "62:3\n",
      "63:ë\n",
      "64:5\n",
      "65:7\n",
      "66:%\n",
      "67:9\n",
      "68:q\n",
      "69:A\n",
      "70:O\n",
      "71:F\n",
      "72:ï\n",
      "73:Z\n",
      "74:S\n",
      "75:–\n",
      "76:’\n",
      "77:X\n",
      "78:ö\n",
      "79:/\n",
      "80:?\n",
      "81:J\n",
      "82:en\n",
      "83:er\n",
      "84:an\n",
      "85:el\n",
      "86:or\n",
      "87:in\n",
      "88:de\n",
      "89:ie\n",
      "90:ij\n",
      "91:st\n",
      "92:et\n",
      "93:aa\n",
      "94:gen\n",
      "95:ch\n",
      "96:on\n",
      "97:kan\n",
      "98:ge\n",
      "99:van\n",
      "100:ker\n",
      "101:at\n",
      "102:oor\n",
      "103:om\n",
      "104:ver\n",
      "105:kanker\n",
      "106:al\n",
      "107:re\n",
      "108:het\n",
      "109:be\n",
      "110:is\n",
      "111:der\n",
      "112:ro\n",
      "113:ing\n",
      "114:den\n",
      "115:op\n",
      "116:it\n",
      "117:een\n",
      "118:aar\n",
      "119:un\n",
      "120:atie\n",
      "121:cel\n",
      "122:aan\n",
      "123:ken\n",
      "124:oe\n",
      "125:ijk\n",
      "126:ut\n",
      "127:ijn\n",
      "128:len\n",
      "129:te\n",
      "130:nen\n",
      "131:zijn\n",
      "132:of\n",
      "133:del\n",
      "134:um\n",
      "135:ct\n",
      "136:mut\n",
      "137:ar\n",
      "138:genen\n",
      "139:di\n",
      "140:kun\n",
      "141:kunnen\n",
      "142:ze\n",
      "143:nie\n",
      "144:oo\n",
      "145:bij\n",
      "146:ei\n",
      "147:we\n",
      "148:uit\n",
      "149:met\n",
      "150:voor\n",
      "151:wor\n",
      "152:ont\n",
      "153:elijk\n",
      "154:ol\n",
      "155:mutatie\n",
      "156:sch\n",
      "157:door\n",
      "158:eer\n",
      "159:men\n",
      "160:umor\n",
      "161:en.\n",
      "162:cellen\n",
      "163:die\n",
      "164:to\n",
      "165:ich\n",
      "166:tumor\n",
      "167:le\n",
      "168:ook\n",
      "169:che\n",
      "170:og\n",
      "171:ig\n",
      "172:ru\n",
      "173:as\n",
      "174:als\n",
      "175:il\n",
      "176:eld\n",
      "177:eren\n",
      "178:co\n",
      "179:ef\n",
      "180:mutaties\n",
      "181:ul\n",
      "182:gro\n",
      "183:sp\n",
      "184:niet\n",
      "185:worden\n",
      "186:her\n",
      "187:ven\n",
      "188:ten\n",
      "189:vi\n",
      "190:aal\n",
      "191:staan\n",
      "192:onder\n",
      "193:and\n",
      "194:ra\n",
      "195:dt\n",
      "196:uw\n",
      "197:vor\n",
      "198:ingen\n",
      "199:loe\n",
      "200:han\n",
      "201:dat\n",
      "202:me\n",
      "203:groei\n",
      "204:omen\n",
      "205:ische\n",
      "206:deling\n",
      "207:wer\n",
      "208:act\n",
      "209:geb\n",
      "210:ier\n",
      "211:aat\n",
      "212:he\n",
      "213:cht\n",
      "214:ik\n",
      "215:ap\n",
      "216:cin\n",
      "217:oom\n",
      "218:se\n",
      "219:ne\n",
      "220:sel\n",
      "221:sen\n",
      "222:ym\n",
      "223:In\n",
      "224:aak\n",
      "225:pro\n",
      "226:dere\n",
      "227:wel\n",
      "228:ontstaan\n",
      "229:ral\n",
      "230:ree\n",
      "231:daar\n",
      "232:zich\n",
      "233:ot\n",
      "234:gev\n",
      "235:zo\n",
      "236:De\n",
      "237:NA\n",
      "238:ast\n",
      "239:ke\n",
      "240:reg\n",
      "241:DNA\n",
      "242:onco\n",
      "243:do\n",
      "244:inv\n",
      "245:loed\n",
      "246:tot\n",
      "247:car\n",
      "248:carcin\n",
      "249:ect\n",
      "250:mi\n",
      "251:tie\n",
      "252:weef\n",
      "253:weefsel\n",
      "254:vol\n",
      "255:ve\n",
      "256:gene\n",
      "257:Bij\n",
      "258:waar\n",
      "259:behan\n",
      "260:olog\n",
      "261:oorz\n",
      "262:wordt\n",
      "263:gez\n",
      "264:aken\n",
      "265:ur\n",
      "266:stral\n",
      "267:pre\n",
      "268:doen\n",
      "269:lym\n",
      "270:lymf\n",
      "271:beeld\n",
      "272:kanker.\n",
      "273:over\n",
      "274:Het\n",
      "275:af\n",
      "276:zel\n",
      "277:zelf\n",
      "278:orm\n",
      "279:en,\n",
      "280:rus\n",
      "281:im\n",
      "282:zoe\n",
      "283:dig\n",
      "284:lich\n",
      "285:maar\n",
      "286:herap\n",
      "287:ste\n",
      "288:Er\n",
      "289:oord\n",
      "290:eid\n",
      "291:cer\n",
      "292:bet\n",
      "293:rij\n",
      "294:kel\n",
      "295:bep\n",
      "296:fact\n",
      "297:factor\n",
      "298:stof\n",
      "299:deze\n",
      "300:gen.\n",
      "301:schil\n",
      "302:elijke\n",
      "303:ën\n",
      "304:aam\n",
      "305:arm\n",
      "306:kom\n",
      "307:ci\n",
      "308:ologie\n",
      "309:herapie\n",
      "310:us\n",
      "311:ann\n",
      "312:anneer\n",
      "313:es\n",
      "314:virus\n",
      "315:uleren\n",
      "316:werk\n",
      "317:ok\n",
      "318:ben\n",
      "319:andere\n",
      "320:ion\n",
      "321:oncogenen\n",
      "322:mog\n",
      "323:ijd\n",
      "324:onderzoe\n",
      "325:Kan\n",
      "326:Kanker\n",
      "327:iek\n",
      "328:bl\n",
      "329:rei\n",
      "330:scha\n",
      "331:lichaam\n",
      "332:voorbeeld\n",
      "333:darm\n",
      "334:ter\n",
      "335:ho\n",
      "336:behandeling\n",
      "337:Ne\n",
      "338:ang\n",
      "339:kl\n",
      "340:mer\n",
      "341:bepaal\n",
      "342:stoff\n",
      "343:dige\n",
      "344:vaak\n",
      "345:ris\n",
      "346:ico\n",
      "347:oorzaken\n",
      "348:schillen\n",
      "349:schillende\n",
      "350:fect\n",
      "351:kken\n",
      "352:su\n",
      "353:ss\n",
      "354:mogelijk\n",
      "355:reek\n",
      "356:ele\n",
      "357:heid\n",
      "358:rom\n",
      "359:geen\n",
      "360:ende\n",
      "361:echt\n",
      "362:nieu\n",
      "363:nieuwe\n",
      "364:na\n",
      "365:Neder\n",
      "366:Nederl\n",
      "367:Nederland\n",
      "368:carcinoom\n",
      "369:ai\n",
      "370:woord\n",
      "371:hun\n",
      "372:meer\n",
      "373:risico\n",
      "374:verschillende\n",
      "375:erf\n",
      "376:den.\n",
      "377:verb\n",
      "378:gebru\n",
      "379:gebruik\n",
      "380:to-\n",
      "381:press\n",
      "382:t.\n",
      "383:),\n",
      "384:ventie\n",
      "385:vorm\n",
      "386:pl\n",
      "387:metast\n",
      "388:metastas\n",
      "389:mat\n",
      "390:bijvoorbeeld\n",
      "391:ige\n",
      "392:komen\n",
      "393:ds\n",
      "394:eken\n",
      "395:norm\n",
      "396:no\n",
      "397:bepaalde\n",
      "398:stel\n",
      "399:kelijk\n",
      "400:ctie\n",
      "401:invloed\n",
      "402:factoren\n",
      "403:vorder\n",
      "404:ui\n",
      "405:gezwel\n",
      "406:dan\n",
      "407:heb\n",
      "408:igne\n",
      "409:volgen\n",
      "410:uwen\n",
      "411:).\n",
      "412:bor\n",
      "413:borst\n",
      "414:va\n",
      "415:erfelijke\n",
      "416:verh\n",
      "417:verhoo\n",
      "418:verhoog\n",
      "419:os\n",
      "420:straling\n",
      "421:veroorzaken\n",
      "422:br\n",
      "423:am\n",
      "424:sup\n",
      "425:suppress\n",
      "426:suppressor\n",
      "427:suppressorgenen\n",
      "428:DNA-\n",
      "429:tijd\n",
      "430:wij\n",
      "431:iën\n",
      "432:reeks\n",
      "433:tumoren\n",
      "434:onderzoek\n",
      "435:isch\n",
      "436:mal\n",
      "437:nieuw\n",
      "438:tr\n",
      "439:naar\n",
      "440:via\n",
      "441:vat\n",
      "442:bloed\n",
      "443:kankercellen\n",
      "444:bel\n",
      "445:aast\n",
      "446:spe\n",
      "447:kanker,\n",
      "448:onc\n",
      "449:otherapie\n",
      "450:20\n",
      "451:ancer\n",
      "452:kt\n",
      "453:ab\n",
      "454:rol\n",
      "455:eerde\n",
      "456:li\n",
      "457:zoals\n",
      "458:org\n",
      "459:krij\n",
      "460:ex\n",
      "461:tra\n",
      "462:mische\n",
      "463:wen\n",
      "464:soor\n",
      "465:soorten\n",
      "466:bevorder\n",
      "467:regel\n",
      "468:Wanneer\n",
      "469:pen\n",
      "470:amen\n",
      "471:hebben\n",
      "472:ale\n",
      "473:ling\n",
      "474:staat\n",
      "475:man\n",
      "476:rouwen\n",
      "477:ster\n",
      "478:elden\n",
      "479:RC\n",
      "480:vormen\n",
      "481:mid\n",
      "482:middel\n",
      "483:stoffen\n",
      "484:opt\n",
      "485:proto-\n",
      "486:tumorsuppressorgenen\n",
      "487:kans\n",
      "488:ontw\n",
      "489:ontwik\n",
      "490:Al\n",
      "491:sl\n",
      "492:muta\n",
      "493:recht\n",
      "494:rechtst\n",
      "495:som\n",
      "496:pt\n",
      "497:pijn\n",
      "498:ag\n",
      "499:pe\n",
      "500:opl\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T10:15:12.592438Z",
     "start_time": "2025-12-12T10:15:12.587518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"cancer_wiki.enc\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ],
   "id": "9b3a561c43b2da6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:C\n",
      "2:a\n",
      "3:n\n",
      "4:c\n",
      "5:e\n",
      "6:r\n",
      "7:i\n",
      "8:s\n",
      "9:g\n",
      "10:o\n",
      "11:u\n",
      "12:p\n",
      "13:f\n",
      "14:d\n",
      "15:v\n",
      "16:l\n",
      "17:b\n",
      "18:m\n",
      "19:w\n",
      "20:t\n",
      "21:h\n",
      "22:y\n",
      "23:.\n",
      "24:[\n",
      "25:2\n",
      "26:]\n",
      "27:7\n",
      "28:T\n",
      "29:,\n",
      "30:P\n",
      "31:x\n",
      "32:1\n",
      "33:W\n",
      "34:O\n",
      "35:0\n",
      "36:8\n",
      "37:A\n",
      "38:3\n",
      "39:%\n",
      "40:k\n",
      "41:9\n",
      "42:z\n",
      "43:I\n",
      "44:6\n",
      "45:–\n",
      "46:H\n",
      "47:B\n",
      "48:V\n",
      "49:E\n",
      "50:-\n",
      "51:K\n",
      "52:'\n",
      "53:M\n",
      "54:(\n",
      "55:)\n",
      "56:q\n",
      "57:5\n",
      "58:4\n",
      "59:F\n",
      "60:U\n",
      "61:S\n",
      "62:R\n",
      "63:$\n",
      "64:D\n",
      "65::\n",
      "66:G\n",
      "67:κ\n",
      "68:α\n",
      "69:ρ\n",
      "70:ί\n",
      "71:ν\n",
      "72:ο\n",
      "73:ς\n",
      "74:L\n",
      "75:\"\n",
      "76:;\n",
      "77:/\n",
      "78:N\n",
      "79:j\n",
      "80:J\n",
      "81:X\n",
      "82:Y\n",
      "83:~\n",
      "84:—\n",
      "85:an\n",
      "86:er\n",
      "87:in\n",
      "88:th\n",
      "89:re\n",
      "90:at\n",
      "91:on\n",
      "92:en\n",
      "93:es\n",
      "94:al\n",
      "95:anc\n",
      "96:or\n",
      "97:is\n",
      "98:ancer\n",
      "99:the\n",
      "100:ed\n",
      "101:as\n",
      "102:cancer\n",
      "103:of\n",
      "104:om\n",
      "105:ion\n",
      "106:ic\n",
      "107:ar\n",
      "108:and\n",
      "109:to\n",
      "110:.[\n",
      "111:ing\n",
      "112:le\n",
      "113:ent\n",
      "114:el\n",
      "115:us\n",
      "116:it\n",
      "117:ro\n",
      "118:ct\n",
      "119:ation\n",
      "120:de\n",
      "121:iv\n",
      "122:su\n",
      "123:st\n",
      "124:ly\n",
      "125:ch\n",
      "126:are\n",
      "127:et\n",
      "128:ther\n",
      "129:mo\n",
      "130:ut\n",
      "131:ag\n",
      "132:lo\n",
      "133:im\n",
      "134:ad\n",
      "135:ig\n",
      "136:pro\n",
      "137:no\n",
      "138:co\n",
      "139:he\n",
      "140:ap\n",
      "141:for\n",
      "142:be\n",
      "143:wi\n",
      "144:un\n",
      "145:com\n",
      "146:ir\n",
      "147:that\n",
      "148:op\n",
      "149:ment\n",
      "150:fe\n",
      "151:gen\n",
      "152:ur\n",
      "153:ive\n",
      "154:ul\n",
      "155:am\n",
      "156:s,\n",
      "157:pe\n",
      "158:ast\n",
      "159:se\n",
      "160:ell\n",
      "161:.[2\n",
      "162:il\n",
      "163:.[1\n",
      "164:inc\n",
      "165:ab\n",
      "166:aus\n",
      "167:with\n",
      "168:pre\n",
      "169:caus\n",
      "170:cell\n",
      "171:du\n",
      "172:wh\n",
      "173:ma\n",
      "174:ex\n",
      "175:av\n",
      "176:reat\n",
      "177:um\n",
      "178:rom\n",
      "179:di\n",
      "180:by\n",
      "181:li\n",
      "182:ce\n",
      "183:ical\n",
      "184:ter\n",
      "185:treat\n",
      "186:con\n",
      "187:tr\n",
      "188:ty\n",
      "189:ain\n",
      "190:cancers\n",
      "191:ris\n",
      "192:so\n",
      "193:po\n",
      "194:risk\n",
      "195:The\n",
      "196:fect\n",
      "197:dis\n",
      "198:art\n",
      "199:therap\n",
      "200:id\n",
      "201:ver\n",
      "202:][\n",
      "203:not\n",
      "204:may\n",
      "205:can\n",
      "206:oma\n",
      "207:act\n",
      "208:ome\n",
      "209:all\n",
      "210:ss\n",
      "211:mp\n",
      "212:lu\n",
      "213:cancer,\n",
      "214:od\n",
      "215:from\n",
      "216:cause\n",
      "217:treatment\n",
      "218:mon\n",
      "219:ac\n",
      "220:vel\n",
      "221:igh\n",
      "222:hav\n",
      "223:ate\n",
      "224:ity\n",
      "225:ated\n",
      "226:cin\n",
      "227:ne\n",
      "228:qu\n",
      "229:ef\n",
      "230:sy\n",
      "231:ho\n",
      "232:reas\n",
      "233:est\n",
      "234:umor\n",
      "235:ib\n",
      "236:ath\n",
      "237:sur\n",
      "238:car\n",
      "239:therapy\n",
      "240:age\n",
      "241:ations\n",
      "242:ial\n",
      "243:tumor\n",
      "244:iation\n",
      "245:end\n",
      "246:have\n",
      "247:mal\n",
      "248:ary\n",
      "249:em\n",
      "250:typ\n",
      "251:sis\n",
      "252:Cancer\n",
      "253:ug\n",
      "254:ant\n",
      "255:In\n",
      "256:ess\n",
      "257:ies\n",
      "258:und\n",
      "259:20\n",
      "260:ure\n",
      "261:carcin\n",
      "262:other\n",
      "263:inclu\n",
      "264:adiation\n",
      "265:bre\n",
      "266:oc\n",
      "267:if\n",
      "268:6]\n",
      "269:ople\n",
      "270:Th\n",
      "271:pat\n",
      "272:such\n",
      "273:we\n",
      "274:ors\n",
      "275:io\n",
      "276:increas\n",
      "277:breast\n",
      "278:artic\n",
      "279:NA\n",
      "280:eas\n",
      "281:ign\n",
      "282:genes\n",
      "283:ative\n",
      "284:most\n",
      "285:ol\n",
      "286:death\n",
      "287:iz\n",
      "288:5]\n",
      "289:common\n",
      "290:ple\n",
      "291:per\n",
      "292:some\n",
      "293:9]\n",
      "294:ates\n",
      "295:mut\n",
      "296:out\n",
      "297:3]\n",
      "298:etic\n",
      "299:devel\n",
      "300:develop\n",
      "301:4]\n",
      "302:hy\n",
      "303:diseas\n",
      "304:mpt\n",
      "305:ugh\n",
      "306:vir\n",
      "307:wor\n",
      "308:than\n",
      "309:cur\n",
      "310:s.\n",
      "311:fer\n",
      "312:DNA\n",
      "313:1]\n",
      "314:rect\n",
      "315:ient\n",
      "316:met\n",
      "317:ese\n",
      "318:ich\n",
      "319:ill\n",
      "320:pr\n",
      "321:any\n",
      "322:te\n",
      "323:med\n",
      "324:ang\n",
      "325:8]\n",
      "326:radiation\n",
      "327:agno\n",
      "328:people\n",
      "329:ung\n",
      "330:sp\n",
      "331:vent\n",
      "332:lon\n",
      "333:ve\n",
      "334:ia\n",
      "335:ort\n",
      "336:more\n",
      "337:ding\n",
      "338:low\n",
      "339:),\n",
      "340:has\n",
      "341:inv\n",
      "342:which\n",
      "343:0]\n",
      "344:2]\n",
      "345:sc\n",
      "346:occur\n",
      "347:form\n",
      "348:high\n",
      "349:7]\n",
      "350:fact\n",
      "351:cer\n",
      "352:pec\n",
      "353:diagno\n",
      "354:one\n",
      "355:astas\n",
      "356:effect\n",
      "357:ally\n",
      "358:rep\n",
      "359:00\n",
      "360:types\n",
      "361:ely\n",
      "362:ear\n",
      "363:lung\n",
      "364:gy\n",
      "365:cells\n",
      "366:carcinoma\n",
      "367:gro\n",
      "368:include\n",
      "369:test\n",
      "370:patient\n",
      "371:care\n",
      "372:kin\n",
      "373:able\n",
      "374:ide\n",
      "375:ist\n",
      "376:ev\n",
      "377:also\n",
      "378:ans\n",
      "379:'s\n",
      "380:requ\n",
      "381:reen\n",
      "382:ke\n",
      "383:ger\n",
      "384:air\n",
      "385:des\n",
      "386:mptom\n",
      "387:pl\n",
      "388:es,\n",
      "389:due\n",
      "390:me\n",
      "391:surv\n",
      "392:19\n",
      "393:ere\n",
      "394:article\n",
      "395:press\n",
      "396:alter\n",
      "397:symptom\n",
      "398:ight\n",
      "399:ld\n",
      "400:reening\n",
      "401:ced\n",
      "402:disease\n",
      "403:exam\n",
      "404:ine\n",
      "405:This\n",
      "406:used\n",
      "407:.[9\n",
      "408:up\n",
      "409:ormal\n",
      "410:do\n",
      "411:fic\n",
      "412:but\n",
      "413:cas\n",
      "414:iver\n",
      "415:was\n",
      "416:ass\n",
      "417:prog\n",
      "418:issu\n",
      "419:ep\n",
      "420:Main\n",
      "421:rel\n",
      "422:normal\n",
      "423:factors\n",
      "424:spec\n",
      "425:tho\n",
      "426:been\n",
      "427:fo\n",
      "428:screening\n",
      "429:redu\n",
      "430:who\n",
      "431:emo\n",
      "432:ular\n",
      "433:ival\n",
      "434:ions\n",
      "435:blo\n",
      "436:article:\n",
      "437:repair\n",
      "438:grow\n",
      "439:ody\n",
      "440:chang\n",
      "441:10\n",
      "442:ited\n",
      "443:thro\n",
      "444:colo\n",
      "445:about\n",
      "446:div\n",
      "447:tissu\n",
      "448:ces\n",
      "449:this\n",
      "450:eli\n",
      "451:body\n",
      "452:symptoms\n",
      "453:ile\n",
      "454:af\n",
      "455:ob\n",
      "456:sure\n",
      "457:ll\n",
      "458:virus\n",
      "459:world\n",
      "460:wn\n",
      "461:its\n",
      "462:dec\n",
      "463:non\n",
      "464:cr\n",
      "465:produ\n",
      "466:romo\n",
      "467:metastas\n",
      "468:ult\n",
      "469:ence\n",
      "470:prevent\n",
      "471:sign\n",
      "472:deaths\n",
      "473:get\n",
      "474:red\n",
      "475:inh\n",
      "476:king\n",
      "477:heal\n",
      "478:ten\n",
      "479:chemo\n",
      "480:ance\n",
      "481:diagnosis\n",
      "482:For\n",
      "483:over\n",
      "484:bl\n",
      "485:example\n",
      "486:Some\n",
      "487:ay\n",
      "488:ogen\n",
      "489:mutations\n",
      "490:bet\n",
      "491:comm\n",
      "492:commend\n",
      "493:tent\n",
      "494:ible\n",
      "495:caused\n",
      "496:][1\n",
      "497:tain\n",
      "498:infect\n",
      "499:ific\n",
      "500:lymp\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Nu we 2 verschillende tokenizers hebben gemaakt, namelijk die van de Nederlandse wikipedia pagina en de Nederlandse, gaan we de methode tokenize gebruiken op beide pagina's. Waarbij elke pagina door zowel de Nederlandse als de Engelse tokenizer geencodeerd zal worden. Dit levert in totaal 4 geencodeerde bestanden op.",
   "id": "672a6df309f8777f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T10:05:08.313566Z",
     "start_time": "2025-12-12T10:05:07.803881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoderen van nederlandse wiki met nederlandse tokenizer\n",
    "!python tokenizer.py tokenize resources\\kanker_wiki.txt .\\kanker_wiki.enc"
   ],
   "id": "21010d55492f7e99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens saved: C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\kanker_wiki.tok\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T10:05:16.128771Z",
     "start_time": "2025-12-12T10:05:15.634161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoderen van nederlandse wiki met engelse tokenizer\n",
    "!python tokenizer.py tokenize resources\\kanker_wiki.txt .\\cancer_wiki.enc"
   ],
   "id": "753fa700a97e4110",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001B[35m\"C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\tokenizer.py\"\u001B[0m, line \u001B[35m160\u001B[0m, in \u001B[35m<module>\u001B[0m\n",
      "    \u001B[31mmain\u001B[0m\u001B[1;31m()\u001B[0m\n",
      "    \u001B[31m~~~~\u001B[0m\u001B[1;31m^^\u001B[0m\n",
      "  File \u001B[35m\"C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\tokenizer.py\"\u001B[0m, line \u001B[35m127\u001B[0m, in \u001B[35mmain\u001B[0m\n",
      "    w_tok.append(\u001B[31mtok_to_id\u001B[0m\u001B[1;31m[w[i]]\u001B[0m)\n",
      "                 \u001B[31m~~~~~~~~~\u001B[0m\u001B[1;31m^^^^^^\u001B[0m\n",
      "\u001B[1;35mKeyError\u001B[0m: \u001B[35m'é'\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T10:05:46.967492Z",
     "start_time": "2025-12-12T10:05:46.331356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoderen van engelse wiki met engelse tokenizer\n",
    "!python tokenizer.py tokenize resources\\cancer_wiki.txt .\\cancer_wiki.enc"
   ],
   "id": "16f0ce3615bcb90e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens saved: C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\cancer_wiki.tok\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T10:05:49.034979Z",
     "start_time": "2025-12-12T10:05:48.491413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoderen van engelse wiki met nederlandse tokenizer\n",
    "!python tokenizer.py tokenize resources\\cancer_wiki.txt .\\kanker_wiki.enc"
   ],
   "id": "9cbd0cdf307dc0a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001B[35m\"C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\tokenizer.py\"\u001B[0m, line \u001B[35m160\u001B[0m, in \u001B[35m<module>\u001B[0m\n",
      "    \u001B[31mmain\u001B[0m\u001B[1;31m()\u001B[0m\n",
      "    \u001B[31m~~~~\u001B[0m\u001B[1;31m^^\u001B[0m\n",
      "  File \u001B[35m\"C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\tokenizer.py\"\u001B[0m, line \u001B[35m127\u001B[0m, in \u001B[35mmain\u001B[0m\n",
      "    w_tok.append(\u001B[31mtok_to_id\u001B[0m\u001B[1;31m[w[i]]\u001B[0m)\n",
      "                 \u001B[31m~~~~~~~~~\u001B[0m\u001B[1;31m^^^^^^\u001B[0m\n",
      "\u001B[1;35mKeyError\u001B[0m: \u001B[35m'$'\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Het encoderen lijkt alleen goed te gaan als de juiste tokenizer wordt gebruikt. Bij het gebruiken van de Nederlandse tokenizer op de Engelse tekst, is er een error, omdat het teken '$', niet bestaat binnen de Nederlandse tokenizer. Hetzelfde geldt bij het gebruik van de Engelse tokenizer op de Nederlandse tekst, er is dan ook een error, omdat het teken 'é' niet bestaat binnen de Engelse tokenizer. Een oplossing hiervoor zou zijn om sowieso alle tekens in de tokenizers te zetten, ook al komen ze niet in de tekst voor. Maar dan is de vraag waar het limiet is, want dan zou je bijvoorbeeld ook alle chinese tekens etc. er in moeten zetten, als je zeker wil weten dat een Nederlandse tokenizer zou werken op Chinese tekst. Dit zou helemaal niet efficient zijn.",
   "id": "900d8c696ea994e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "De teksten die wel juist zijn geencodeerd zijn de Nederlandse wiki met de Nederlandse tokenizer en de Engelse wiki met de Engelse tokenizer. Hieronder zijn de resultaten te zien.",
   "id": "f47e0489b4af4170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T10:13:59.586606Z",
     "start_time": "2025-12-12T10:13:59.580345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"kanker_wiki.tok\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents[1:100])"
   ],
   "id": "cfba7c930ac6be07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 7\n",
      "87\n",
      "202 139 156\n",
      "14 101 127 17\n",
      "219 500 173 9 2\n",
      "436 171 3 134 17\n",
      "23 4 24 93 231 283 7\n",
      "437 234 278\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T10:14:01.037211Z",
     "start_time": "2025-12-12T10:14:01.031352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"cancer_wiki.tok\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents[1:100])"
   ],
   "id": "7a2c332ad4ffe89b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "97\n",
      "2\n",
      "367 408\n",
      "103\n",
      "402 8\n",
      "341 285 15 111\n",
      "165 422\n",
      "170\n",
      "438 88\n",
      "167\n",
      "99\n",
      "193 493 242\n",
      "109\n",
      "341 134 5\n",
      "96\n",
      "330\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
