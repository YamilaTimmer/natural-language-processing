{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Toepassing Tokenizer\n",
    "\n",
    "In dit notebook passen we de tokenizer toe op 2 teksten, namelijk de wikipedia pagina van kanker in het Nederlands en in het Engels. Eerst gebruiken we de learn methode om de tokenizer te trainen op de teksten. Hieruit volgen .enc bestanden die alle gemaakte tokens en de bijbehorende tekens bevatten. We geven 2 argumenten mee, max_tokens om het maximale aantal tokens vast te stellen, in dit geval op 500. En min_freq, om vast te stellen hoe vaak een of meerdere tekens moeten voorkomen om een token te vormen, in dit geval is dat 5."
   ],
   "id": "6a15618c883dfbd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:28:40.082320Z",
     "start_time": "2025-12-13T17:28:38.510765Z"
    }
   },
   "cell_type": "code",
   "source": "!python tokenizer.py learn -i resources\\kanker_wiki.txt -t 500 -f 5",
   "id": "141036ca36eebbe6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding saved: C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\kanker_wiki.enc\n",
      "BPE learned! Max tokens respected: 500\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:28:45.767407Z",
     "start_time": "2025-12-13T17:28:41.837623Z"
    }
   },
   "cell_type": "code",
   "source": "!python tokenizer.py learn -i resources\\cancer_wiki.txt -t 500 -f 5",
   "id": "8bc83ff0de0bbef5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding saved: C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\cancer_wiki.enc\n",
      "BPE learned! Max tokens respected: 500\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We kunnen de aangemaakte tokens nu bekijken.",
   "id": "4e0a90965cf01c4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:28:48.175506Z",
     "start_time": "2025-12-13T17:28:48.171720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"kanker_wiki.enc\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ],
   "id": "62151b74a654c814",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:k\n",
      "2:a\n",
      "3:n\n",
      "4:e\n",
      "5:r\n",
      "6:,\n",
      "7:i\n",
      "8:m\n",
      "9:d\n",
      "10:s\n",
      "11:c\n",
      "12:h\n",
      "13:l\n",
      "14:t\n",
      "15:j\n",
      "16::\n",
      "17:o\n",
      "18:p\n",
      "19:g\n",
      "20:u\n",
      "21:'\n",
      "22:w\n",
      "23:v\n",
      "24:f\n",
      "25:z\n",
      "26:b\n",
      "27:;\n",
      "28:y\n",
      "29:.\n",
      "30:-\n",
      "31:2\n",
      "32:0\n",
      "33:8\n",
      "34:(\n",
      "35:)\n",
      "36:\"\n",
      "37:[\n",
      "38:1\n",
      "39:]\n",
      "40:x\n",
      "41:é\n",
      "42:ó\n",
      "43:6\n",
      "44:4\n",
      "45:3\n",
      "46:ë\n",
      "47:5\n",
      "48:7\n",
      "49:%\n",
      "50:9\n",
      "51:q\n",
      "52:ï\n",
      "53:–\n",
      "54:’\n",
      "55:ö\n",
      "56:/\n",
      "57:?\n",
      "58:en\n",
      "59:er\n",
      "60:de\n",
      "61:an\n",
      "62:ge\n",
      "63:el\n",
      "64:ie\n",
      "65:in\n",
      "66:or\n",
      "67:ke\n",
      "68:aa\n",
      "69:ee\n",
      "70:re\n",
      "71:et\n",
      "72:ij\n",
      "73:he\n",
      "74:oo\n",
      "75:ne\n",
      "76:st\n",
      "77:va\n",
      "78:le\n",
      "79:nd\n",
      "80:te\n",
      "81:ti\n",
      "82:ve\n",
      "83:ka\n",
      "84:li\n",
      "85:ch\n",
      "86:me\n",
      "87:on\n",
      "88:at\n",
      "89:ng\n",
      "90:al\n",
      "91:nk\n",
      "92:be\n",
      "93:ro\n",
      "94:rd\n",
      "95:om\n",
      "96:ar\n",
      "97:ta\n",
      "98:oe\n",
      "99:es\n",
      "100:is\n",
      "101:we\n",
      "102:nt\n",
      "103:di\n",
      "104:ce\n",
      "105:ll\n",
      "106:to\n",
      "107:vo\n",
      "108:zi\n",
      "109:ni\n",
      "110:ra\n",
      "111:ed\n",
      "112:sc\n",
      "113:op\n",
      "114:ma\n",
      "115:it\n",
      "116:ev\n",
      "117:se\n",
      "118:ek\n",
      "119:da\n",
      "120:mo\n",
      "121:ld\n",
      "122:tr\n",
      "123:bi\n",
      "124:un\n",
      "125:og\n",
      "126:ig\n",
      "127:mu\n",
      "128:rs\n",
      "129:ri\n",
      "130:nn\n",
      "131:ze\n",
      "132:ui\n",
      "133:jk\n",
      "134:ut\n",
      "135:jn\n",
      "136:pr\n",
      "137:la\n",
      "138:ei\n",
      "139:wo\n",
      "140:na\n",
      "141:as\n",
      "142:ic\n",
      "143:do\n",
      "144:lo\n",
      "145:ha\n",
      "146:tu\n",
      "147:ec\n",
      "148:ok\n",
      "149:rm\n",
      "150:of\n",
      "151:no\n",
      "152:ol\n",
      "153:ct\n",
      "154:um\n",
      "155:ot\n",
      "156:ak\n",
      "157:rk\n",
      "158:ns\n",
      "159:zo\n",
      "160:ca\n",
      "161:ku\n",
      "162:co\n",
      "163:mi\n",
      "164:ef\n",
      "165:fe\n",
      "166:ez\n",
      "167:pe\n",
      "168:ts\n",
      "169:eg\n",
      "170:ls\n",
      "171:id\n",
      "172:em\n",
      "173:nc\n",
      "174:rg\n",
      "175:rc\n",
      "176:wa\n",
      "177:gr\n",
      "178:vi\n",
      "179:pa\n",
      "180:ho\n",
      "181:si\n",
      "182:ac\n",
      "183:so\n",
      "184:am\n",
      "185:ru\n",
      "186:ci\n",
      "187:rz\n",
      "188:eu\n",
      "189:br\n",
      "190:hi\n",
      "191:ir\n",
      "192:uw\n",
      "193:ul\n",
      "194:il\n",
      "195:gi\n",
      "196:wi\n",
      "197:ht\n",
      "198:eb\n",
      "199:rb\n",
      "200:ag\n",
      "201:pi\n",
      "202:sp\n",
      "203:th\n",
      "204:kt\n",
      "205:kk\n",
      "206:ko\n",
      "207:ep\n",
      "208:us\n",
      "209:ss\n",
      "210:za\n",
      "211:ia\n",
      "212:rt\n",
      "213:ur\n",
      "214:eh\n",
      "215:rv\n",
      "216:dt\n",
      "217:jd\n",
      "218:bl\n",
      "219:ki\n",
      "220:fs\n",
      "221:ik\n",
      "222:ap\n",
      "223:ad\n",
      "224:ym\n",
      "225:io\n",
      "226:ov\n",
      "227:hu\n",
      "228:pt\n",
      "229:vl\n",
      "230:ds\n",
      "231:bo\n",
      "232:rl\n",
      "233:ga\n",
      "234:ff\n",
      "235:mm\n",
      "236:ba\n",
      "237:rw\n",
      "238:gn\n",
      "239:lg\n",
      "240:nv\n",
      "241:ou\n",
      "242:af\n",
      "243:os\n",
      "244:dn\n",
      "245:rn\n",
      "246:od\n",
      "247:nm\n",
      "248:im\n",
      "249:pl\n",
      "250:sm\n",
      "251:lt\n",
      "252:ai\n",
      "253:ly\n",
      "254:tk\n",
      "255:lf\n",
      "256:su\n",
      "257:tt\n",
      "258:fa\n",
      "259:rf\n",
      "260:mf\n",
      "261:fo\n",
      "262:tg\n",
      "263:ks\n",
      "264:dr\n",
      "265:pp\n",
      "266:tw\n",
      "267:kl\n",
      "268:gd\n",
      "269:gs\n",
      "270:ew\n",
      "271:ën\n",
      "272:nu\n",
      "273:jv\n",
      "274:fi\n",
      "275:if\n",
      "276:rh\n",
      "277:nw\n",
      "278:oc\n",
      "279:ex\n",
      "280:zw\n",
      "281:sa\n",
      "282:ië\n",
      "283:dw\n",
      "284:gg\n",
      "285:kr\n",
      "286:ms\n",
      "287:mp\n",
      "288:mg\n",
      "289:vr\n",
      "290:nl\n",
      "291:ft\n",
      "292:eo\n",
      "293:md\n",
      "294:gt\n",
      "295:sk\n",
      "296:hr\n",
      "297:lu\n",
      "298:gu\n",
      "299:ib\n",
      "300:bb\n",
      "301:uk\n",
      "302:lv\n",
      "303:eë\n",
      "304:dd\n",
      "305:up\n",
      "306:mt\n",
      "307:zu\n",
      "308:ea\n",
      "309:uc\n",
      "310:vu\n",
      "311:tz\n",
      "312:po\n",
      "313:bu\n",
      "314:kh\n",
      "315:ud\n",
      "316:ip\n",
      "317:ab\n",
      "318:oa\n",
      "319:jg\n",
      "320:ue\n",
      "321:yp\n",
      "322:av\n",
      "323:du\n",
      "324:sl\n",
      "325:sy\n",
      "326:kw\n",
      "327:nf\n",
      "328:mk\n",
      "329:rp\n",
      "330:iv\n",
      "331:ty\n",
      "332:fu\n",
      "333:go\n",
      "334:ja\n",
      "335:gk\n",
      "336:fr\n",
      "337:ob\n",
      "338:ix\n",
      "339:tl\n",
      "340:lc\n",
      "341:dv\n",
      "342:hy\n",
      "343:fw\n",
      "344:uu\n",
      "345:cu\n",
      "346:kan\n",
      "347:van\n",
      "348:ank\n",
      "349:ker\n",
      "350:gen\n",
      "351:het\n",
      "352:ver\n",
      "353:ing\n",
      "354:een\n",
      "355:atie\n",
      "356:cel\n",
      "357:ijn\n",
      "358:den\n",
      "359:der\n",
      "360:len\n",
      "361:bij\n",
      "362:zij\n",
      "363:nen\n",
      "364:aan\n",
      "365:ord\n",
      "366:ell\n",
      "367:enen\n",
      "368:eren\n",
      "369:voor\n",
      "370:nie\n",
      "371:kun\n",
      "372:unn\n",
      "373:ijk\n",
      "374:ende\n",
      "375:del\n",
      "376:mut\n",
      "377:tat\n",
      "378:aar\n",
      "379:wor\n",
      "380:met\n",
      "381:and\n",
      "382:ies\n",
      "383:ken\n",
      "384:ont\n",
      "385:ook\n",
      "386:sch\n",
      "387:tum\n",
      "388:mor\n",
      "389:uit\n",
      "390:door\n",
      "391:die\n",
      "392:ten\n",
      "393:erk\n",
      "394:che\n",
      "395:lin\n",
      "396:als\n",
      "397:eld\n",
      "398:men\n",
      "399:elij\n",
      "400:tst\n",
      "401:ere\n",
      "402:sta\n",
      "403:nder\n",
      "404:iet\n",
      "405:ent\n",
      "406:gro\n",
      "407:omen\n",
      "408:pro\n",
      "409:str\n",
      "410:oed\n",
      "411:dat\n",
      "412:ond\n",
      "413:oren\n",
      "414:ogen\n",
      "415:maa\n",
      "416:daa\n",
      "417:ers\n",
      "418:han\n",
      "419:cht\n",
      "420:onc\n",
      "421:oor\n",
      "422:roei\n",
      "423:isc\n",
      "424:oom\n",
      "425:orm\n",
      "426:ven\n",
      "427:beel\n",
      "428:wer\n",
      "429:aal\n",
      "430:ijd\n",
      "431:gel\n",
      "432:tie\n",
      "433:lij\n",
      "434:chi\n",
      "435:vor\n",
      "436:her\n",
      "437:cin\n",
      "438:erd\n",
      "439:org\n",
      "440:zich\n",
      "441:beh\n",
      "442:arc\n",
      "443:deze\n",
      "444:wee\n",
      "445:erst\n",
      "446:oek\n",
      "447:ande\n",
      "448:dna\n",
      "449:ral\n",
      "450:erz\n",
      "451:orbe\n",
      "452:tot\n",
      "453:aak\n",
      "454:cer\n",
      "455:llen\n",
      "456:ijke\n",
      "457:cog\n",
      "458:gev\n",
      "459:eefs\n",
      "460:fsel\n",
      "461:naa\n",
      "462:wan\n",
      "463:waa\n",
      "464:orz\n",
      "465:over\n",
      "466:ordt\n",
      "467:ens\n",
      "468:ect\n",
      "469:end\n",
      "470:lich\n",
      "471:erl\n",
      "472:aat\n",
      "473:zel\n",
      "474:bet\n",
      "475:vloe\n",
      "476:sti\n",
      "477:viru\n",
      "478:vaa\n",
      "479:ill\n",
      "480:zoe\n",
      "481:ter\n",
      "482:olog\n",
      "483:kel\n",
      "484:neer\n",
      "485:bep\n",
      "486:invl\n",
      "487:kom\n",
      "488:fact\n",
      "489:ctor\n",
      "490:stof\n",
      "491:fen\n",
      "492:erw\n",
      "493:car\n",
      "494:ree\n",
      "495:aard\n",
      "496:volg\n",
      "497:dig\n",
      "498:chaa\n",
      "499:erin\n",
      "500:lym\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:28:51.210493Z",
     "start_time": "2025-12-13T17:28:51.206421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"cancer_wiki.enc\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ],
   "id": "9b3a561c43b2da6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:c\n",
      "2:a\n",
      "3:n\n",
      "4:e\n",
      "5:r\n",
      "6:i\n",
      "7:s\n",
      "8:g\n",
      "9:o\n",
      "10:u\n",
      "11:p\n",
      "12:f\n",
      "13:d\n",
      "14:v\n",
      "15:l\n",
      "16:b\n",
      "17:m\n",
      "18:w\n",
      "19:t\n",
      "20:h\n",
      "21:y\n",
      "22:.\n",
      "23:[\n",
      "24:2\n",
      "25:]\n",
      "26:7\n",
      "27:,\n",
      "28:x\n",
      "29:1\n",
      "30:0\n",
      "31:8\n",
      "32:3\n",
      "33:%\n",
      "34:k\n",
      "35:9\n",
      "36:z\n",
      "37:6\n",
      "38:–\n",
      "39:-\n",
      "40:'\n",
      "41:(\n",
      "42:)\n",
      "43:q\n",
      "44:5\n",
      "45:4\n",
      "46:$\n",
      "47::\n",
      "48:κ\n",
      "49:α\n",
      "50:ρ\n",
      "51:ί\n",
      "52:ν\n",
      "53:ο\n",
      "54:ς\n",
      "55:\"\n",
      "56:;\n",
      "57:/\n",
      "58:j\n",
      "59:~\n",
      "60:—\n",
      "61:an\n",
      "62:th\n",
      "63:er\n",
      "64:in\n",
      "65:re\n",
      "66:ca\n",
      "67:he\n",
      "68:ce\n",
      "69:at\n",
      "70:ti\n",
      "71:on\n",
      "72:nc\n",
      "73:en\n",
      "74:es\n",
      "75:or\n",
      "76:al\n",
      "77:ar\n",
      "78:is\n",
      "79:ed\n",
      "80:se\n",
      "81:nd\n",
      "82:as\n",
      "83:te\n",
      "84:ea\n",
      "85:st\n",
      "86:io\n",
      "87:of\n",
      "88:to\n",
      "89:ve\n",
      "90:ma\n",
      "91:me\n",
      "92:nt\n",
      "93:om\n",
      "94:ro\n",
      "95:ng\n",
      "96:ic\n",
      "97:it\n",
      "98:le\n",
      "99:ta\n",
      "100:de\n",
      "101:co\n",
      "102:ra\n",
      "103:di\n",
      "104:ne\n",
      "105:ha\n",
      "106:el\n",
      "107:si\n",
      "108:ll\n",
      "109:mo\n",
      "110:ge\n",
      "111:ri\n",
      "112:pr\n",
      "113:us\n",
      "114:no\n",
      "115:li\n",
      "116:ec\n",
      "117:rs\n",
      "118:ch\n",
      "119:ct\n",
      "120:ly\n",
      "121:su\n",
      "122:lo\n",
      "123:ur\n",
      "124:os\n",
      "125:pe\n",
      "126:ia\n",
      "127:ns\n",
      "128:iv\n",
      "129:et\n",
      "130:ot\n",
      "131:tr\n",
      "132:la\n",
      "133:ou\n",
      "134:be\n",
      "135:hi\n",
      "136:na\n",
      "137:ci\n",
      "138:ss\n",
      "139:fo\n",
      "140:pa\n",
      "141:so\n",
      "142:vi\n",
      "143:ho\n",
      "144:ol\n",
      "145:fe\n",
      "146:ie\n",
      "147:op\n",
      "148:ev\n",
      "149:mi\n",
      "150:ut\n",
      "151:ts\n",
      "152:un\n",
      "153:ad\n",
      "154:ac\n",
      "155:ag\n",
      "156:il\n",
      "157:ir\n",
      "158:im\n",
      "159:em\n",
      "160:wi\n",
      "161:ty\n",
      "162:rt\n",
      "163:ig\n",
      "164:ni\n",
      "165:mp\n",
      "166:ap\n",
      "167:po\n",
      "168:ai\n",
      "169:cl\n",
      "170:ee\n",
      "171:pl\n",
      "172:cr\n",
      "173:ul\n",
      "174:rc\n",
      "175:uc\n",
      "176:am\n",
      "177:tu\n",
      "178:lu\n",
      "179:id\n",
      "180:du\n",
      "181:wh\n",
      "182:bl\n",
      "183:oc\n",
      "184:rm\n",
      "185:au\n",
      "186:fi\n",
      "187:ow\n",
      "188:va\n",
      "189:ex\n",
      "190:og\n",
      "191:ep\n",
      "192:ab\n",
      "193:ls\n",
      "194:mm\n",
      "195:um\n",
      "196:ry\n",
      "197:gn\n",
      "198:if\n",
      "199:ef\n",
      "200:lt\n",
      "201:od\n",
      "202:gh\n",
      "203:cu\n",
      "204:av\n",
      "205:sk\n",
      "206:fr\n",
      "207:we\n",
      "208:pi\n",
      "209:sp\n",
      "210:mu\n",
      "211:ay\n",
      "212:by\n",
      "213:bo\n",
      "214:ue\n",
      "215:yp\n",
      "216:sc\n",
      "217:ff\n",
      "218:gr\n",
      "219:cc\n",
      "220:ud\n",
      "221:ov\n",
      "222:wo\n",
      "223:ph\n",
      "224:rg\n",
      "225:ke\n",
      "226:br\n",
      "227:tm\n",
      "228:ei\n",
      "229:gi\n",
      "230:eo\n",
      "231:pt\n",
      "232:fa\n",
      "233:bi\n",
      "234:py\n",
      "235:sy\n",
      "236:ld\n",
      "237:ki\n",
      "238:hy\n",
      "239:rr\n",
      "240:ib\n",
      "241:qu\n",
      "242:ru\n",
      "243:oo\n",
      "244:ms\n",
      "245:pp\n",
      "246:nv\n",
      "247:ga\n",
      "248:sh\n",
      "249:rv\n",
      "250:ys\n",
      "251:ym\n",
      "252:eg\n",
      "253:rl\n",
      "254:sa\n",
      "255:ug\n",
      "256:hr\n",
      "257:sm\n",
      "258:ba\n",
      "259:do\n",
      "260:nf\n",
      "261:bu\n",
      "262:xp\n",
      "263:ua\n",
      "264:da\n",
      "265:up\n",
      "266:ob\n",
      "267:iz\n",
      "268:dn\n",
      "269:fu\n",
      "270:eq\n",
      "271:wa\n",
      "272:tl\n",
      "273:dy\n",
      "274:ny\n",
      "275:ds\n",
      "276:ui\n",
      "277:dr\n",
      "278:ew\n",
      "279:rn\n",
      "280:rd\n",
      "281:vo\n",
      "282:af\n",
      "283:ht\n",
      "284:eu\n",
      "285:gl\n",
      "286:gy\n",
      "287:tt\n",
      "288:hs\n",
      "289:xi\n",
      "290:ft\n",
      "291:oi\n",
      "292:ik\n",
      "293:cy\n",
      "294:ze\n",
      "295:xa\n",
      "296:ps\n",
      "297:tw\n",
      "298:hu\n",
      "299:yl\n",
      "300:nl\n",
      "301:ye\n",
      "302:ub\n",
      "303:gu\n",
      "304:ox\n",
      "305:mb\n",
      "306:ey\n",
      "307:ck\n",
      "308:wn\n",
      "309:nh\n",
      "310:fl\n",
      "311:bs\n",
      "312:gs\n",
      "313:lv\n",
      "314:ok\n",
      "315:ak\n",
      "316:ip\n",
      "317:uk\n",
      "318:oa\n",
      "319:wt\n",
      "320:nu\n",
      "321:dd\n",
      "322:nm\n",
      "323:lc\n",
      "324:zi\n",
      "325:dv\n",
      "326:yn\n",
      "327:oh\n",
      "328:rk\n",
      "329:xc\n",
      "330:lp\n",
      "331:oe\n",
      "332:go\n",
      "333:cs\n",
      "334:kn\n",
      "335:yc\n",
      "336:nk\n",
      "337:lf\n",
      "338:sl\n",
      "339:ix\n",
      "340:pu\n",
      "341:ka\n",
      "342:ks\n",
      "343:jo\n",
      "344:bn\n",
      "345:xt\n",
      "346:nn\n",
      "347:aj\n",
      "348:tc\n",
      "349:pm\n",
      "350:ju\n",
      "351:uf\n",
      "352:dw\n",
      "353:yo\n",
      "354:sf\n",
      "355:my\n",
      "356:bc\n",
      "357:lk\n",
      "358:lm\n",
      "359:ws\n",
      "360:rb\n",
      "361:rf\n",
      "362:ja\n",
      "363:yi\n",
      "364:dl\n",
      "365:ml\n",
      "366:sw\n",
      "367:pn\n",
      "368:np\n",
      "369:iu\n",
      "370:sq\n",
      "371:hn\n",
      "372:yr\n",
      "373:dj\n",
      "374:can\n",
      "375:cer\n",
      "376:the\n",
      "377:anc\n",
      "378:and\n",
      "379:ing\n",
      "380:ati\n",
      "381:ion\n",
      "382:ther\n",
      "383:ent\n",
      "384:ers\n",
      "385:pro\n",
      "386:for\n",
      "387:are\n",
      "388:men\n",
      "389:tion\n",
      "390:that\n",
      "391:with\n",
      "392:com\n",
      "393:ons\n",
      "394:cell\n",
      "395:gen\n",
      "396:reat\n",
      "397:ast\n",
      "398:tic\n",
      "399:pre\n",
      "400:tre\n",
      "401:ter\n",
      "402:use\n",
      "403:reas\n",
      "404:con\n",
      "405:ris\n",
      "406:dis\n",
      "407:cal\n",
      "408:tas\n",
      "409:orm\n",
      "410:isk\n",
      "411:mor\n",
      "412:may\n",
      "413:atm\n",
      "414:ors\n",
      "415:not\n",
      "416:cre\n",
      "417:erap\n",
      "418:fec\n",
      "419:omm\n",
      "420:from\n",
      "421:cau\n",
      "422:mon\n",
      "423:oth\n",
      "424:ive\n",
      "425:res\n",
      "426:tum\n",
      "427:ents\n",
      "428:ity\n",
      "429:oma\n",
      "430:some\n",
      "431:apy\n",
      "432:ated\n",
      "433:ene\n",
      "434:have\n",
      "435:ate\n",
      "436:ally\n",
      "437:carc\n",
      "438:rcin\n",
      "439:radi\n",
      "440:inc\n",
      "441:ary\n",
      "442:mal\n",
      "443:pat\n",
      "444:bre\n",
      "445:most\n",
      "446:this\n",
      "447:ble\n",
      "448:incl\n",
      "449:diat\n",
      "450:such\n",
      "451:dea\n",
      "452:vir\n",
      "453:ver\n",
      "454:arti\n",
      "455:all\n",
      "456:peop\n",
      "457:ople\n",
      "458:eath\n",
      "459:used\n",
      "460:enes\n",
      "461:sis\n",
      "462:utat\n",
      "463:duce\n",
      "464:nos\n",
      "465:met\n",
      "466:par\n",
      "467:caus\n",
      "468:ere\n",
      "469:ces\n",
      "470:inf\n",
      "471:wor\n",
      "472:med\n",
      "473:ance\n",
      "474:tive\n",
      "475:mut\n",
      "476:enti\n",
      "477:ten\n",
      "478:ted\n",
      "479:end\n",
      "480:ven\n",
      "481:ecti\n",
      "482:tal\n",
      "483:eti\n",
      "484:deve\n",
      "485:velo\n",
      "486:lls\n",
      "487:one\n",
      "488:red\n",
      "489:than\n",
      "490:dna\n",
      "491:call\n",
      "492:che\n",
      "493:more\n",
      "494:ates\n",
      "495:sion\n",
      "496:lat\n",
      "497:ich\n",
      "498:out\n",
      "499:tis\n",
      "500:any\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Nu we 2 verschillende tokenizers hebben gemaakt, namelijk die van de Nederlandse wikipedia pagina en de Nederlandse, gaan we de methode tokenize gebruiken op beide pagina's. Waarbij elke pagina door zowel de Nederlandse als de Engelse tokenizer geencodeerd zal worden. Dit levert in totaal 4 geencodeerde bestanden op.",
   "id": "672a6df309f8777f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:29:01.872883Z",
     "start_time": "2025-12-13T17:29:01.252670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoderen van nederlandse wiki met nederlandse tokenizer\n",
    "!python tokenizer.py tokenize -i resources\\kanker_wiki.txt -e .\\kanker_wiki.enc"
   ],
   "id": "21010d55492f7e99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens saved: C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\kanker_wiki.tok\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:29:09.072624Z",
     "start_time": "2025-12-13T17:29:08.485265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoderen van nederlandse wiki met engelse tokenizer\n",
    "!python tokenizer.py tokenize -i resources\\kanker_wiki.txt -e .\\cancer_wiki.enc"
   ],
   "id": "753fa700a97e4110",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001B[35m\"C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\tokenizer.py\"\u001B[0m, line \u001B[35m175\u001B[0m, in \u001B[35m<module>\u001B[0m\n",
      "    \u001B[31mmain\u001B[0m\u001B[1;31m()\u001B[0m\n",
      "    \u001B[31m~~~~\u001B[0m\u001B[1;31m^^\u001B[0m\n",
      "  File \u001B[35m\"C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\tokenizer.py\"\u001B[0m, line \u001B[35m144\u001B[0m, in \u001B[35mmain\u001B[0m\n",
      "    w_tok.append(\u001B[31mtok_to_id\u001B[0m\u001B[1;31m[w[i]]\u001B[0m)\n",
      "                 \u001B[31m~~~~~~~~~\u001B[0m\u001B[1;31m^^^^^^\u001B[0m\n",
      "\u001B[1;35mKeyError\u001B[0m: \u001B[35m'é'\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:29:17.377677Z",
     "start_time": "2025-12-13T17:29:16.755231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoderen van engelse wiki met engelse tokenizer\n",
    "!python tokenizer.py tokenize -i resources\\cancer_wiki.txt -e .\\cancer_wiki.enc"
   ],
   "id": "16f0ce3615bcb90e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens saved: C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\cancer_wiki.tok\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:29:25.314471Z",
     "start_time": "2025-12-13T17:29:24.418732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoderen van engelse wiki met nederlandse tokenizer\n",
    "!python tokenizer.py tokenize -i resources\\cancer_wiki.txt -e .\\kanker_wiki.enc"
   ],
   "id": "9cbd0cdf307dc0a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001B[35m\"C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\tokenizer.py\"\u001B[0m, line \u001B[35m175\u001B[0m, in \u001B[35m<module>\u001B[0m\n",
      "    \u001B[31mmain\u001B[0m\u001B[1;31m()\u001B[0m\n",
      "    \u001B[31m~~~~\u001B[0m\u001B[1;31m^^\u001B[0m\n",
      "  File \u001B[35m\"C:\\Users\\yamil\\OneDrive - Hanze\\Bio-informatica\\Jaar 3\\3.3 Modelling Cancer\\natural-language-processing\\tokenizer.py\"\u001B[0m, line \u001B[35m144\u001B[0m, in \u001B[35mmain\u001B[0m\n",
      "    w_tok.append(\u001B[31mtok_to_id\u001B[0m\u001B[1;31m[w[i]]\u001B[0m)\n",
      "                 \u001B[31m~~~~~~~~~\u001B[0m\u001B[1;31m^^^^^^\u001B[0m\n",
      "\u001B[1;35mKeyError\u001B[0m: \u001B[35m'$'\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Het encoderen lijkt alleen goed te gaan als de juiste tokenizer wordt gebruikt. Bij het gebruiken van de Nederlandse tokenizer op de Engelse tekst, is er een error, omdat het teken '$', niet bestaat binnen de Nederlandse tokenizer. Hetzelfde geldt bij het gebruik van de Engelse tokenizer op de Nederlandse tekst, er is dan ook een error, omdat het teken 'é' niet bestaat binnen de Engelse tokenizer. Een oplossing hiervoor zou zijn om sowieso alle tekens in de tokenizers te zetten, ook al komen ze niet in de tekst voor. Maar dan is de vraag waar het limiet is, want dan zou je bijvoorbeeld ook alle chinese tekens etc. er in moeten zetten, als je zeker wil weten dat een Nederlandse tokenizer zou werken op Chinese tekst. Dit zou helemaal niet efficient zijn.",
   "id": "900d8c696ea994e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "De teksten die wel juist zijn geencodeerd zijn de Nederlandse wiki met de Nederlandse tokenizer en de Engelse wiki met de Engelse tokenizer. Hieronder zijn de resultaten te zien.",
   "id": "f47e0489b4af4170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:29:28.513668Z",
     "start_time": "2025-12-13T17:29:28.509574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"kanker_wiki.tok\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents[1:100])"
   ],
   "id": "cfba7c930ac6be07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 349 6\n",
      "65\n",
      "86 103 386\n",
      "137 81 135 16\n",
      "75 113 137 250 2\n",
      "114 84 238 154 16\n",
      "21 326 68 416 94 126 6\n",
      "370 \n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T17:29:30.352052Z",
     "start_time": "2025-12-13T17:29:30.347718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r\"cancer_wiki.tok\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.read()\n",
    "    print(contents[1:100])"
   ],
   "id": "7a2c332ad4ffe89b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 375\n",
      "78\n",
      "2\n",
      "218 133 11\n",
      "87\n",
      "406 84 80 7\n",
      "64 281 313 379\n",
      "192 114 184 76\n",
      "394\n",
      "218 187 62\n",
      "391\n",
      "376\n",
      "167 477 \n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
